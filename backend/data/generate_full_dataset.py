"""
ç”Ÿæˆå®Œæ•´æ•°æ®é›† - åŒ…å«æ‰€æœ‰åœºæ™¯å’Œæ¼”åŒ–ç±»å‹
"""

from data_generator import DataGenerator
from datetime import datetime, timedelta


def generate_comprehensive_dataset():
    """ç”Ÿæˆç»¼åˆæ•°æ®é›†"""
    print("=" * 70)
    print("ç”Ÿæˆå®Œæ•´æ•°æ®é›†")
    print("=" * 70)

    generator = DataGenerator()

    # 1. ç”Ÿæˆæ‰€æœ‰æ¼”åŒ–ç±»å‹çš„æ—¶åºæ•°æ®
    print("\nğŸ“Š ç¬¬1éƒ¨åˆ†: æ—¶åºæ¼”åŒ–æ•°æ®")
    print("-" * 70)

    evolution_types = ["gradual_discharge", "gradual_overheating", "sudden_fault"]
    devices = ["T001", "T002", "D001"]

    for evolution_type in evolution_types:
        for device_id in devices[:2]:  # åªç”¨å‰ä¸¤ä¸ªè®¾å¤‡
            print(f"  ç”Ÿæˆ {device_id} - {evolution_type}...")
            timeseries = generator.generate_timeseries(
                device_id=device_id,
                evolution_type=evolution_type,
                sampling_interval_hours=24
            )
            filename_base = f"timeseries_{device_id}_{evolution_type}"
            generator.export_to_json(timeseries, f"{filename_base}.json")
            generator.export_to_csv(timeseries, f"{filename_base}.csv")

    # 2. ç”Ÿæˆæ‰€æœ‰è¿è¡Œå·¥å†µä¸‹çš„è®¾å¤‡å¿«ç…§
    print("\nğŸ“Š ç¬¬2éƒ¨åˆ†: è¿è¡Œå·¥å†µæ•°æ®")
    print("-" * 70)

    operating_conditions = list(generator.device_templates["operating_conditions"].keys())

    for op_cond in operating_conditions:
        print(f"  ç”Ÿæˆå·¥å†µ: {op_cond}...")
        snapshots = []
        for device in generator.device_templates["device_instances"]:
            snapshot = generator.generate_device_snapshot(
                device_id=device["id"],
                fault_type="normal",
                operating_condition=op_cond
            )
            snapshots.append(snapshot)

        generator.export_to_json(snapshots, f"operating_{op_cond}.json")

    # 3. ç”Ÿæˆå¤šè®¾å¤‡åœºæ™¯
    print("\nğŸ“Š ç¬¬3éƒ¨åˆ†: å¤šè®¾å¤‡åœºæ™¯")
    print("-" * 70)

    scenarios = ["all_normal", "mixed", "multiple_faults"]
    for scenario in scenarios:
        print(f"  ç”Ÿæˆåœºæ™¯: {scenario}...")
        multi_device = generator.generate_multi_device_data(scenario=scenario)
        generator.export_to_json(multi_device, f"scenario_{scenario}.json")

    # 4. ç”Ÿæˆæ¯ç§æ•…éšœç±»å‹åœ¨ä¸åŒè´Ÿè½½ä¸‹çš„æ•°æ®
    print("\nğŸ“Š ç¬¬4éƒ¨åˆ†: æ•…éšœç±»å‹ Ã— è´Ÿè½½ç»„åˆ")
    print("-" * 70)

    fault_types = list(generator.fault_profiles["fault_types"].keys())
    load_conditions = ["light_load", "normal", "overload"]

    for fault_type in fault_types:
        print(f"  ç”Ÿæˆæ•…éšœç±»å‹: {fault_type}...")
        snapshots = []
        for load_cond in load_conditions:
            snapshot = generator.generate_device_snapshot(
                device_id="T001",
                fault_type=fault_type,
                operating_condition=load_cond
            )
            snapshots.append(snapshot)

        generator.export_to_json(snapshots, f"fault_{fault_type}_by_load.json")

    # 5. ç”Ÿæˆé•¿æœŸå†å²æ•°æ®ï¼ˆ365å¤©ï¼‰
    print("\nğŸ“Š ç¬¬5éƒ¨åˆ†: é•¿æœŸå†å²æ•°æ®")
    print("-" * 70)

    print("  ç”Ÿæˆ T001 å…¨å¹´æ•°æ®ï¼ˆæ­£å¸¸è¿è¡Œï¼‰...")
    start_date = datetime.now() - timedelta(days=365)
    long_term_data = []

    for day in range(365):
        current_date = start_date + timedelta(days=day)

        # æ¨¡æ‹Ÿå­£èŠ‚æ€§è´Ÿè½½å˜åŒ–
        if 150 <= day <= 240:  # å¤å­£
            op_cond = "summer_peak"
        elif day <= 60 or day >= 330:  # å†¬å­£
            op_cond = "winter_peak"
        else:
            op_cond = "normal"

        snapshot = generator.generate_device_snapshot(
            device_id="T001",
            fault_type="normal",
            operating_condition=op_cond,
            timestamp=current_date
        )
        long_term_data.append(snapshot)

    generator.export_to_json(long_term_data, "history_T001_365days.json")
    generator.export_to_csv(long_term_data, "history_T001_365days.csv")

    # 6. ç”Ÿæˆæ•°æ®é›†æ±‡æ€»ä¿¡æ¯
    print("\nğŸ“Š ç¬¬6éƒ¨åˆ†: æ•°æ®é›†æ±‡æ€»")
    print("-" * 70)

    summary = {
        "generation_date": datetime.now().isoformat(),
        "total_devices": len(generator.device_templates["device_instances"]),
        "device_types": list(generator.device_templates["device_types"].keys()),
        "fault_types": fault_types,
        "evolution_types": evolution_types,
        "operating_conditions": operating_conditions,
        "datasets": {
            "timeseries_evolution": f"{len(evolution_types)} * {len(devices[:2])} = {len(evolution_types) * len(devices[:2])} files",
            "operating_conditions": f"{len(operating_conditions)} files",
            "multi_device_scenarios": f"{len(scenarios)} files",
            "fault_load_combinations": f"{len(fault_types)} files",
            "long_term_history": "1 file (365 days)"
        },
        "total_files": (
            len(evolution_types) * len(devices[:2]) * 2 +  # timeseries (json + csv)
            len(operating_conditions) +
            len(scenarios) +
            len(fault_types) +
            2  # long-term (json + csv)
        )
    }

    generator.export_to_json(summary, "dataset_summary.json")

    print("\n" + "=" * 70)
    print(f"âœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
    print(f"   æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
    print(f"   è¾“å‡ºç›®å½•: backend/data/generated/")
    print("=" * 70)

    return summary


if __name__ == "__main__":
    summary = generate_comprehensive_dataset()
