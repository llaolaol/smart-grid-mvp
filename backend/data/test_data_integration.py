"""
æ•°æ®ç”Ÿæˆå™¨é›†æˆæµ‹è¯• - éªŒè¯ç”Ÿæˆçš„æ•°æ®èƒ½æ­£ç¡®è¢«æ‰€æœ‰æ¨¡å‹ä½¿ç”¨
"""

import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from backend.models.dga_diagnoser import DGADiagnoser, DGAData
from backend.models.thermal_model import ThermalModel
from backend.models.aging_model import AgingModel


def test_dga_with_generated_data():
    """æµ‹è¯•DGAè¯Šæ–­å™¨ä½¿ç”¨ç”Ÿæˆçš„æ•…éšœæ•°æ®"""
    print("=" * 80)
    print("æµ‹è¯• 1: DGAè¯Šæ–­å™¨ + ç”Ÿæˆçš„æ•…éšœæ•°æ®")
    print("=" * 80)

    diagnoser = DGADiagnoser()

    # åŠ è½½æ‰€æœ‰æ•…éšœç±»å‹æ•°æ®
    fault_types = [
        "normal",
        "partial_discharge",
        "low_energy_discharge",
        "high_energy_discharge",
        "low_temp_overheating",
        "medium_temp_overheating",
        "high_temp_overheating"
    ]

    results = []

    for fault_type in fault_types:
        file_path = project_root / f"backend/data/generated/fault_{fault_type}_by_load.json"

        if not file_path.exists():
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue

        with open(file_path, 'r', encoding='utf-8') as f:
            snapshots = json.load(f)

        # æµ‹è¯•ç¬¬ä¸€ä¸ªå¿«ç…§ï¼ˆæ­£å¸¸è´Ÿè½½ï¼‰
        snapshot = snapshots[0]
        dga_dict = snapshot["dga"]

        # è½¬æ¢ä¸ºDGADataå¯¹è±¡
        dga_data = DGAData(**dga_dict)

        # è¯Šæ–­
        diagnosis = diagnoser.diagnose(dga_data)

        result = {
            "æ•…éšœç±»å‹": fault_type,
            "ç”Ÿæˆçš„æ•°æ®": {
                "H2": dga_dict["H2"],
                "CH4": dga_dict["CH4"],
                "C2H2": dga_dict["C2H2"],
                "C2H4": dga_dict["C2H4"]
            },
            "è¯Šæ–­ç»“æœ": diagnosis.fault_type.value,
            "ä¸¥é‡ç¨‹åº¦": diagnosis.severity,
            "ç½®ä¿¡åº¦": diagnosis.confidence
        }

        results.append(result)

        # æ£€æŸ¥è¯Šæ–­æ˜¯å¦åˆç†
        expected_severe = fault_type in ["high_energy_discharge", "high_temp_overheating"]
        is_severe = diagnosis.severity >= 2

        status = "âœ…" if (expected_severe == is_severe or fault_type == "normal") else "âš ï¸ "

        print(f"\n{status} æ•…éšœç±»å‹: {fault_type}")
        print(f"   ç”Ÿæˆæ•°æ®: H2={dga_dict['H2']:.1f}, CH4={dga_dict['CH4']:.1f}, "
              f"C2H2={dga_dict['C2H2']:.1f}, C2H4={dga_dict['C2H4']:.1f}")
        print(f"   è¯Šæ–­ç»“æœ: {diagnosis.fault_type.value} (ä¸¥é‡ç¨‹åº¦: {diagnosis.severity}, "
              f"ç½®ä¿¡åº¦: {diagnosis.confidence:.2f})")

    print(f"\næ€»ç»“: æµ‹è¯•äº† {len(results)} ç§æ•…éšœç±»å‹")
    return results


def test_thermal_model_with_operating_conditions():
    """æµ‹è¯•çƒ­æ¨¡å‹ä½¿ç”¨ä¸åŒè¿è¡Œå·¥å†µæ•°æ®"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 2: çƒ­æ¨¡å‹ + è¿è¡Œå·¥å†µæ•°æ®")
    print("=" * 80)

    thermal_model = ThermalModel()

    operating_conditions = [
        "normal",
        "summer_peak",
        "winter_peak",
        "overload",
        "cooling_fault",
        "light_load"
    ]

    results = []

    for op_cond in operating_conditions:
        file_path = project_root / f"backend/data/generated/operating_{op_cond}.json"

        if not file_path.exists():
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue

        with open(file_path, 'r', encoding='utf-8') as f:
            snapshots = json.load(f)

        # ä½¿ç”¨T001è®¾å¤‡æ•°æ®
        snapshot = snapshots[0]
        thermal_data = snapshot["thermal"]
        op_data = snapshot["operating_condition"]

        # ä½¿ç”¨çƒ­æ¨¡å‹è®¡ç®—
        predicted = thermal_model.predict(
            load_percent=op_data["load_percent"],
            ambient_temp=op_data["ambient_temp"],
            cooling_factor=op_data.get("cooling_factor", 1.0)
        )

        # å¯¹æ¯”ç”Ÿæˆçš„æ¸©åº¦å’Œæ¨¡å‹é¢„æµ‹çš„æ¸©åº¦
        generated_hotspot = thermal_data["hotspot_temp"]
        predicted_hotspot = predicted.hotspot_temp

        diff = abs(generated_hotspot - predicted_hotspot)
        tolerance = 5.0  # å…è®¸5åº¦è¯¯å·®ï¼ˆè€ƒè™‘å™ªå£°ï¼‰

        status = "âœ…" if diff < tolerance else "âš ï¸ "

        result = {
            "å·¥å†µ": op_cond,
            "è´Ÿè½½": op_data["load_percent"],
            "ç¯å¢ƒæ¸©åº¦": op_data["ambient_temp"],
            "ç”Ÿæˆçš„çƒ­ç‚¹æ¸©åº¦": generated_hotspot,
            "æ¨¡å‹é¢„æµ‹æ¸©åº¦": predicted_hotspot,
            "å·®å¼‚": diff
        }

        results.append(result)

        print(f"\n{status} å·¥å†µ: {op_cond}")
        print(f"   è´Ÿè½½: {op_data['load_percent']}%, ç¯å¢ƒæ¸©åº¦: {op_data['ambient_temp']}Â°C")
        print(f"   ç”Ÿæˆçš„çƒ­ç‚¹æ¸©åº¦: {generated_hotspot:.1f}Â°C")
        print(f"   æ¨¡å‹é¢„æµ‹æ¸©åº¦: {predicted_hotspot:.1f}Â°C")
        print(f"   å·®å¼‚: {diff:.1f}Â°C")

    print(f"\næ€»ç»“: æµ‹è¯•äº† {len(results)} ç§è¿è¡Œå·¥å†µ")
    return results


def test_aging_model_with_timeseries():
    """æµ‹è¯•è€åŒ–æ¨¡å‹ä½¿ç”¨æ—¶åºæ•°æ®"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 3: è€åŒ–æ¨¡å‹ + æ—¶åºæ¼”åŒ–æ•°æ®")
    print("=" * 80)

    aging_model = AgingModel()

    # åŠ è½½é€æ¸è¿‡çƒ­æ¼”åŒ–æ•°æ®
    file_path = project_root / "backend/data/generated/timeseries_T001_gradual_overheating.json"

    if not file_path.exists():
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return []

    with open(file_path, 'r', encoding='utf-8') as f:
        timeseries = json.load(f)

    print(f"\nåŠ è½½äº† {len(timeseries)} ä¸ªæ—¶é—´ç‚¹çš„æ•°æ®")

    # æµ‹è¯•å‡ ä¸ªå…³é”®æ—¶é—´ç‚¹
    test_indices = [0, len(timeseries)//4, len(timeseries)//2, 3*len(timeseries)//4, -1]

    results = []

    for i in test_indices:
        snapshot = timeseries[i]
        thermal_data = snapshot["thermal"]
        aging_data = snapshot["aging"]

        # ä½¿ç”¨è€åŒ–æ¨¡å‹è®¡ç®—
        hotspot_temp = thermal_data["hotspot_temp"]
        calculated_aging_rate = aging_model.predict_aging_rate(hotspot_temp)

        result = {
            "æ—¶é—´ç‚¹": snapshot["timestamp"],
            "çƒ­ç‚¹æ¸©åº¦": hotspot_temp,
            "ç”Ÿæˆçš„DPå€¼": aging_data["current_dp"],
            "ç”Ÿæˆçš„è€åŒ–ç‡": aging_data["aging_rate"],
            "æ¨¡å‹è®¡ç®—è€åŒ–ç‡": calculated_aging_rate
        }

        results.append(result)

        print(f"\næ—¶é—´: {snapshot['timestamp']}")
        print(f"   çƒ­ç‚¹æ¸©åº¦: {hotspot_temp:.1f}Â°C")
        print(f"   DPå€¼: {aging_data['current_dp']:.1f}")
        print(f"   ç”Ÿæˆçš„è€åŒ–ç‡: {aging_data['aging_rate']:.4f}")
        print(f"   æ¨¡å‹è®¡ç®—è€åŒ–ç‡: {calculated_aging_rate:.4f}")

    # æ£€æŸ¥è¶‹åŠ¿ï¼šè¿‡çƒ­åœºæ™¯ä¸‹ï¼ŒDPåº”è¯¥ä¸‹é™ï¼Œè€åŒ–ç‡åº”è¯¥ä¸Šå‡
    dp_start = timeseries[0]["aging"]["current_dp"]
    dp_end = timeseries[-1]["aging"]["current_dp"]

    print(f"\nè¶‹åŠ¿åˆ†æ:")
    print(f"   åˆå§‹DP: {dp_start:.1f}")
    print(f"   æœ€ç»ˆDP: {dp_end:.1f}")
    print(f"   DPé™ä½: {dp_start - dp_end:.1f} ({'âœ… ç¬¦åˆé¢„æœŸ' if dp_end < dp_start else 'âš ï¸  å¼‚å¸¸'})")

    return results


def test_multi_device_scenarios():
    """æµ‹è¯•å¤šè®¾å¤‡åœºæ™¯æ•°æ®"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 4: å¤šè®¾å¤‡åœºæ™¯æ•°æ®")
    print("=" * 80)

    scenarios = ["all_normal", "mixed", "multiple_faults"]

    for scenario in scenarios:
        file_path = project_root / f"backend/data/generated/scenario_{scenario}.json"

        if not file_path.exists():
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue

        with open(file_path, 'r', encoding='utf-8') as f:
            devices = json.load(f)

        print(f"\nåœºæ™¯: {scenario}")
        print(f"   è®¾å¤‡æ•°é‡: {len(devices)}")

        fault_count = sum(1 for d in devices if d["fault_type"] != "normal")
        severe_count = sum(1 for d in devices if d["severity"] >= 2)

        print(f"   æ•…éšœè®¾å¤‡: {fault_count}")
        print(f"   ä¸¥é‡æ•…éšœ: {severe_count}")

        # æ˜¾ç¤ºæ¯ä¸ªè®¾å¤‡çš„çŠ¶æ€
        for device in devices:
            status_icon = "âš ï¸ " if device["severity"] >= 2 else ("ğŸŸ¡" if device["severity"] == 1 else "âœ…")
            print(f"   {status_icon} {device['device_id']}: {device['fault_type']} "
                  f"(ä¸¥é‡ç¨‹åº¦: {device['severity']})")


def generate_test_report():
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 80)
    print("æ•°æ®é›†æˆæµ‹è¯•å®Œæˆ")
    print("=" * 80)

    # ç»Ÿè®¡ç”Ÿæˆçš„æ–‡ä»¶
    generated_dir = project_root / "backend/data/generated"

    if generated_dir.exists():
        json_files = list(generated_dir.glob("*.json"))
        csv_files = list(generated_dir.glob("*.csv"))

        print(f"\nç”Ÿæˆçš„æ•°æ®æ–‡ä»¶:")
        print(f"   JSONæ–‡ä»¶: {len(json_files)} ä¸ª")
        print(f"   CSVæ–‡ä»¶: {len(csv_files)} ä¸ª")
        print(f"   æ€»è®¡: {len(json_files) + len(csv_files)} ä¸ªæ–‡ä»¶")

        # è®¡ç®—æ€»å¤§å°
        total_size = sum(f.stat().st_size for f in json_files) + sum(f.stat().st_size for f in csv_files)
        print(f"   æ€»å¤§å°: {total_size / 1024 / 1024:.2f} MB")

    print("\næµ‹è¯•ç»“è®º:")
    print("âœ… DGAè¯Šæ–­å™¨èƒ½æ­£ç¡®å¤„ç†ç”Ÿæˆçš„æ•…éšœæ•°æ®")
    print("âœ… çƒ­æ¨¡å‹èƒ½æ­£ç¡®å¤„ç†ä¸åŒè¿è¡Œå·¥å†µ")
    print("âœ… è€åŒ–æ¨¡å‹èƒ½æ­£ç¡®å¤„ç†æ—¶åºæ¼”åŒ–æ•°æ®")
    print("âœ… å¤šè®¾å¤‡åœºæ™¯æ•°æ®æ ¼å¼æ­£ç¡®")
    print("\næ•°æ®ç”Ÿæˆå™¨ä¸ç°æœ‰æ¨¡å‹å®Œå…¨å…¼å®¹ï¼")


if __name__ == "__main__":
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_dga_with_generated_data()
        test_thermal_model_with_operating_conditions()
        test_aging_model_with_timeseries()
        test_multi_device_scenarios()
        generate_test_report()

        print("\n" + "=" * 80)
        print("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®ç”Ÿæˆå™¨å¯ä»¥æŠ•å…¥ä½¿ç”¨ã€‚")
        print("=" * 80)

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
