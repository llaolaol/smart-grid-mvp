"""
æ•°æ®åŠ è½½å™¨ - ä¸ºDemoåº”ç”¨æä¾›ä¾¿æ·çš„æ•°æ®è®¿é—®æ¥å£
"""

import json
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime
import pandas as pd
from backend.data.csv_parsers import get_parser


# è®¾å¤‡åˆ°CSVæ–‡ä»¶çš„æ˜ å°„é…ç½®
DEVICE_CSV_MAPPING = {
    "T001": {
        "csv_file": "simulated_oil_chromatography_data.csv",
        "parser_type": "oil",
        "device_name": "1å·ä¸»å˜",
        "device_id": "12M00000159733143",  # CSVä¸­çš„è®¾å¤‡ç¼–å·
    },
    # ä¸“é—¨ç”¨äº CSV Mock æ•°æ®æµ‹è¯•çš„è®¾å¤‡ ID
    "T001_OIL_CSV": {
        "csv_file": "simulated_oil_chromatography_data.csv",
        "parser_type": "oil",
        "device_name": "1å·ä¸»å˜ï¼ˆæ²¹è‰²è°±CSVæ•°æ®ï¼‰",
        "device_id": "12M00000159733143",
    },
    # TODO: åç»­æ·»åŠ  T002 (æœºæ§æ•°æ®), T003 (æ™ºå·¡æ•°æ®)
}


class DataLoader:
    """æ•°æ®åŠ è½½å™¨ - ç»Ÿä¸€æ¥å£è®¿é—®ç”Ÿæˆçš„æ•°æ®é›†"""

    def __init__(self, data_dir: Optional[str] = None, mock_csv_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨

        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸º backend/data/generated/
            mock_csv_dir: Mock CSVæ•°æ®ç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•çš„ data_pic/
        """
        if data_dir is None:
            current_dir = Path(__file__).parent
            self.data_dir = current_dir / "generated"
        else:
            self.data_dir = Path(data_dir)

        if not self.data_dir.exists():
            raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")

        # é…ç½® Mock CSV æ•°æ®ç›®å½•
        if mock_csv_dir is None:
            # é»˜è®¤æŒ‡å‘é¡¹ç›®æ ¹ç›®å½•çš„ data_pic/
            project_root = Path(__file__).parent.parent.parent
            self.mock_csv_dir = project_root / "data_pic"
        else:
            self.mock_csv_dir = Path(mock_csv_dir)

    def load_device_snapshot(self, device_id: str, fault_type: str = "normal",
                            operating_condition: str = "normal") -> Dict:
        """
        åŠ è½½å•ä¸ªè®¾å¤‡å¿«ç…§

        Args:
            device_id: è®¾å¤‡ID (å¦‚ "T001", "D001")
            fault_type: æ•…éšœç±»å‹
            operating_condition: è¿è¡Œå·¥å†µ

        Returns:
            è®¾å¤‡å¿«ç…§æ•°æ®
        """
        # ä»æ•…éšœ-è´Ÿè½½ç»„åˆæ–‡ä»¶ä¸­åŠ è½½
        fault_file = self.data_dir / f"fault_{fault_type}_by_load.json"

        if not fault_file.exists():
            raise FileNotFoundError(f"æ•…éšœæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {fault_file}")

        with open(fault_file, 'r', encoding='utf-8') as f:
            snapshots = json.load(f)

        # è¿”å›ç¬¬ä¸€ä¸ªå¿«ç…§ï¼ˆæ­£å¸¸è´Ÿè½½ï¼‰
        return snapshots[0] if snapshots else None

    def load_operating_condition(self, operating_condition: str) -> List[Dict]:
        """
        åŠ è½½ç‰¹å®šè¿è¡Œå·¥å†µä¸‹çš„æ‰€æœ‰è®¾å¤‡æ•°æ®

        Args:
            operating_condition: è¿è¡Œå·¥å†µ (normal, summer_peak, winter_peak, overload, cooling_fault, light_load)

        Returns:
            è®¾å¤‡åˆ—è¡¨
        """
        op_file = self.data_dir / f"operating_{operating_condition}.json"

        if not op_file.exists():
            raise FileNotFoundError(f"è¿è¡Œå·¥å†µæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {op_file}")

        with open(op_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def load_scenario(self, scenario: str) -> List[Dict]:
        """
        åŠ è½½å¤šè®¾å¤‡åœºæ™¯

        Args:
            scenario: åœºæ™¯åç§° (all_normal, mixed, multiple_faults)

        Returns:
            è®¾å¤‡åˆ—è¡¨
        """
        scenario_file = self.data_dir / f"scenario_{scenario}.json"

        if not scenario_file.exists():
            raise FileNotFoundError(f"åœºæ™¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {scenario_file}")

        with open(scenario_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def load_timeseries(self, device_id: str, evolution_type: str,
                       format: str = "json") -> List[Dict]:
        """
        åŠ è½½æ—¶åºæ¼”åŒ–æ•°æ®

        Args:
            device_id: è®¾å¤‡ID
            evolution_type: æ¼”åŒ–ç±»å‹ (gradual_discharge, gradual_overheating, sudden_fault)
            format: æ•°æ®æ ¼å¼ ("json" æˆ– "csv")

        Returns:
            æ—¶åºæ•°æ®åˆ—è¡¨
        """
        if format == "json":
            ts_file = self.data_dir / f"timeseries_{device_id}_{evolution_type}.json"

            if not ts_file.exists():
                raise FileNotFoundError(f"æ—¶åºæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {ts_file}")

            with open(ts_file, 'r', encoding='utf-8') as f:
                return json.load(f)

        elif format == "csv":
            ts_file = self.data_dir / f"timeseries_{device_id}_{evolution_type}.csv"

            if not ts_file.exists():
                raise FileNotFoundError(f"æ—¶åºæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {ts_file}")

            df = pd.read_csv(ts_file)
            return df.to_dict('records')

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}ï¼Œè¯·ä½¿ç”¨ 'json' æˆ– 'csv'")

    def load_history(self, device_id: Optional[str] = None) -> List[Dict]:
        """
        åŠ è½½å†å²æ•°æ®æ–‡ä»¶

        æ”¯æŒåŠ è½½æŒ‡å®šè®¾å¤‡çš„å†å²æ•°æ®ï¼Œæˆ–åŠ è½½æ‰€æœ‰å†å²æ•°æ®æ–‡ä»¶ã€‚

        æ•°æ®åŠ è½½ä¼˜å…ˆçº§:
        1. ä¼˜å…ˆä» timeseries JSON æ–‡ä»¶åŠ è½½ï¼ˆgenerated/ ç›®å½•ï¼‰
        2. å¦‚æœJSONä¸å­˜åœ¨ï¼Œå°è¯•ä» CSV Mock æ•°æ®åŠ è½½ï¼ˆdata_pic/ ç›®å½•ï¼‰
        3. å¦‚æœéƒ½ä¸å­˜åœ¨ï¼ŒæŠ›å‡º FileNotFoundError

        Args:
            device_id: è®¾å¤‡IDï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™åŠ è½½æ‰€æœ‰è®¾å¤‡

        Returns:
            å†å²æ•°æ®åˆ—è¡¨

        Raises:
            FileNotFoundError: å†å²æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨
        """
        if device_id:
            # åŠ è½½ç‰¹å®šè®¾å¤‡çš„å†å²æ•°æ®ï¼ˆå°è¯•æ‰€æœ‰æ¼”åŒ–ç±»å‹ï¼‰
            evolution_types = ["gradual_discharge", "gradual_overheating", "sudden_fault"]
            all_data = []

            for evolution_type in evolution_types:
                try:
                    data = self.load_timeseries(device_id, evolution_type)
                    all_data.extend(data)
                except FileNotFoundError:
                    continue

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°timeseriesæ•°æ®ï¼Œå°è¯•ä»CSVåŠ è½½
            if not all_data:
                try:
                    csv_data = self.load_mock_history_csv(device_id)
                    all_data.extend(csv_data)
                except FileNotFoundError:
                    pass  # CSVä¹Ÿä¸å­˜åœ¨ï¼Œç»§ç»­æŠ›å‡ºé”™è¯¯

            if not all_data:
                raise FileNotFoundError(
                    f"è®¾å¤‡ {device_id} çš„å†å²æ•°æ®ä¸å­˜åœ¨\n"
                    f"æœªæ‰¾åˆ° timeseries JSON æ–‡ä»¶ï¼Œä¹Ÿæœªé…ç½® CSV Mock æ•°æ®"
                )

            return all_data
        else:
            # åŠ è½½æ‰€æœ‰è®¾å¤‡çš„å†å²æ•°æ®
            all_data = []
            devices = self.list_available_devices()

            for dev_id in devices:
                try:
                    device_history = self.load_history(dev_id)
                    all_data.extend(device_history)
                except FileNotFoundError:
                    continue

            return all_data

    def filter_by_time_range(
        self,
        data: List[Dict],
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> List[Dict]:
        """
        æŒ‰æ—¶é—´èŒƒå›´è¿‡æ»¤æ•°æ®åˆ—è¡¨

        æ”¯æŒå¤šç§æ—¶é—´å­—æ®µåï¼ˆå…¼å®¹ä¸‰ç±»æ•°æ®æºï¼‰ï¼š
        - timestamp (æ ‡å‡†å­—æ®µ)
        - acquisitiontime (æ²¹è‰²è°±æ•°æ®)
        - aris_time (æœºæ§æ•°æ®)
        - inspect_time (æ™ºå·¡æ•°æ®)

        Args:
            data: æ•°æ®åˆ—è¡¨
            start_time: å¼€å§‹æ—¶é—´ï¼ˆå¯é€‰ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆå¯é€‰ï¼‰

        Returns:
            è¿‡æ»¤åçš„æ•°æ®åˆ—è¡¨
        """
        from datetime import datetime as dt

        if not start_time and not end_time:
            return data  # æ— æ—¶é—´èŒƒå›´é™åˆ¶ï¼Œè¿”å›å…¨éƒ¨æ•°æ®

        filtered = []

        for item in data:
            # å°è¯•æå–æ—¶é—´æˆ³ï¼ˆä¼˜å…ˆçº§ï¼štimestamp > acquisitiontime > aris_time > inspect_timeï¼‰
            timestamp_str = (
                item.get("timestamp") or
                item.get("acquisitiontime") or
                item.get("aris_time") or
                item.get("inspect_time")
            )

            if not timestamp_str:
                continue  # æ— æ—¶é—´æˆ³ï¼Œè·³è¿‡

            # è§£ææ—¶é—´æˆ³
            try:
                # ç§»é™¤ "local" åç¼€
                timestamp_str = str(timestamp_str).replace(" local", "").strip()

                # å°è¯•å¤šç§æ ¼å¼
                timestamp = None
                formats = [
                    "%Y/%m/%d %H:%M:%S",      # 2023/4/3 8:43:00
                    "%Y-%m-%d %H:%M:%S",      # 2023-04-03 08:43:00
                    "%Y-%m-%dT%H:%M:%S",      # 2023-04-03T08:43:00
                ]

                for fmt in formats:
                    try:
                        timestamp = dt.strptime(timestamp_str, fmt)
                        break
                    except ValueError:
                        continue

                # å¦‚æœéƒ½å¤±è´¥ï¼Œå°è¯• ISO è§£æ
                if not timestamp:
                    try:
                        timestamp = dt.fromisoformat(timestamp_str)
                    except ValueError:
                        continue

            except Exception:
                continue  # è§£æå¤±è´¥ï¼Œè·³è¿‡

            # åº”ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤
            if start_time and timestamp < start_time:
                continue
            if end_time and timestamp > end_time:
                continue

            filtered.append(item)

        return filtered

    def load_mock_history_csv(self, device_id: str) -> List[Dict]:
        """
        ä»CSV Mockæ•°æ®åŠ è½½è®¾å¤‡å†å²æ•°æ®

        æ”¯æŒä¸‰ç±»æ•°æ®æº:
        - æ²¹è‰²è°±æ•°æ® (T001)
        - æœºæ§æ•°æ® (T002, å¾…å®ç°)
        - æ™ºå·¡æ•°æ® (T003, å¾…å®ç°)

        Args:
            device_id: è®¾å¤‡ID (å¦‚ "T001", "T002", "T003")

        Returns:
            å†å²æ•°æ®åˆ—è¡¨ (ç»Ÿä¸€çš„ DeviceHistorySnapshot æ ¼å¼)

        Raises:
            FileNotFoundError: è®¾å¤‡æ²¡æœ‰å¯¹åº”çš„CSVæ˜ å°„æˆ–æ–‡ä»¶ä¸å­˜åœ¨
        """
        # æ£€æŸ¥è®¾å¤‡æ˜¯å¦æœ‰CSVæ˜ å°„
        if device_id not in DEVICE_CSV_MAPPING:
            raise FileNotFoundError(
                f"è®¾å¤‡ {device_id} æ²¡æœ‰é…ç½®CSVæ•°æ®æºæ˜ å°„ï¼Œ"
                f"å¯ç”¨è®¾å¤‡: {list(DEVICE_CSV_MAPPING.keys())}"
            )

        mapping = DEVICE_CSV_MAPPING[device_id]
        csv_path = self.mock_csv_dir / mapping["csv_file"]

        # æ£€æŸ¥CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not csv_path.exists():
            raise FileNotFoundError(
                f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}\n"
                f"è¯·ç¡®è®¤ {self.mock_csv_dir} ç›®å½•ä¸‹æœ‰ {mapping['csv_file']}"
            )

        # ä½¿ç”¨è§£æå™¨åŠ è½½CSVæ•°æ®
        parser = get_parser(csv_path, mapping["parser_type"])
        raw_records = parser.parse()

        # å°†CSVä¸­çš„è®¾å¤‡ç¼–å·æ˜ å°„åˆ°ç³»ç»Ÿè®¾å¤‡ID
        for record in raw_records:
            # ä¿ç•™åŸå§‹è®¾å¤‡ç¼–å·ä½œä¸º equip_no
            record["original_device_id"] = record.get("device_id") or record.get("equip_no")
            # ç»Ÿä¸€è®¾ç½®ä¸ºç³»ç»Ÿè®¾å¤‡ID
            record["device_id"] = device_id
            # è®¾ç½®è®¾å¤‡åç§°
            if not record.get("device_name"):
                record["device_name"] = mapping["device_name"]

        return raw_records

    def list_available_devices(self) -> List[str]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è®¾å¤‡ID

        Returns:
            è®¾å¤‡IDåˆ—è¡¨
        """
        # ä»scenario_all_normalä¸­è·å–æ‰€æœ‰è®¾å¤‡
        all_normal = self.load_scenario("all_normal")
        return [device["device_id"] for device in all_normal]

    def list_available_scenarios(self) -> List[str]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„åœºæ™¯

        Returns:
            åœºæ™¯åç§°åˆ—è¡¨
        """
        scenarios = []
        for file in self.data_dir.glob("scenario_*.json"):
            scenario_name = file.stem.replace("scenario_", "")
            scenarios.append(scenario_name)
        return scenarios

    def list_available_fault_types(self) -> List[str]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ•…éšœç±»å‹

        Returns:
            æ•…éšœç±»å‹åˆ—è¡¨
        """
        fault_types = []
        for file in self.data_dir.glob("fault_*_by_load.json"):
            fault_name = file.stem.replace("fault_", "").replace("_by_load", "")
            fault_types.append(fault_name)
        return fault_types

    def get_device_by_id(self, device_id: str, scenario: str = "all_normal") -> Optional[Dict]:
        """
        æ ¹æ®è®¾å¤‡IDè·å–è®¾å¤‡æ•°æ®

        Args:
            device_id: è®¾å¤‡ID
            scenario: åœºæ™¯åç§°

        Returns:
            è®¾å¤‡æ•°æ®ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        devices = self.load_scenario(scenario)
        for device in devices:
            if device["device_id"] == device_id:
                return device
        return None

    def get_summary(self) -> Dict:
        """
        è·å–æ•°æ®é›†æ¦‚è§ˆ

        Returns:
            æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        """
        summary_file = self.data_dir / "dataset_summary.json"

        if summary_file.exists():
            with open(summary_file, 'r', encoding='utf-8') as f:
                return json.load(f)

        # å¦‚æœæ²¡æœ‰summaryæ–‡ä»¶ï¼ŒåŠ¨æ€ç”Ÿæˆ
        return {
            "devices": self.list_available_devices(),
            "scenarios": self.list_available_scenarios(),
            "fault_types": self.list_available_fault_types(),
            "data_directory": str(self.data_dir)
        }


# ä¾¿æ·å‡½æ•°
def get_demo_device(device_id: str = "T001", fault_type: str = "high_energy_discharge") -> Dict:
    """
    å¿«é€Ÿè·å–Demoæ¼”ç¤ºç”¨çš„è®¾å¤‡æ•°æ®

    Args:
        device_id: è®¾å¤‡IDï¼Œé»˜è®¤ "T001"
        fault_type: æ•…éšœç±»å‹ï¼Œé»˜è®¤ "high_energy_discharge"

    Returns:
        è®¾å¤‡å¿«ç…§æ•°æ®
    """
    loader = DataLoader()
    return loader.load_device_snapshot(device_id, fault_type)


def get_demo_scenario(scenario: str = "mixed") -> List[Dict]:
    """
    å¿«é€Ÿè·å–Demoæ¼”ç¤ºç”¨çš„åœºæ™¯æ•°æ®

    Args:
        scenario: åœºæ™¯åç§°ï¼Œé»˜è®¤ "mixed"

    Returns:
        è®¾å¤‡åˆ—è¡¨
    """
    loader = DataLoader()
    return loader.load_scenario(scenario)


def get_demo_timeseries(device_id: str = "T001",
                       evolution_type: str = "gradual_discharge") -> List[Dict]:
    """
    å¿«é€Ÿè·å–Demoæ¼”ç¤ºç”¨çš„æ—¶åºæ•°æ®

    Args:
        device_id: è®¾å¤‡IDï¼Œé»˜è®¤ "T001"
        evolution_type: æ¼”åŒ–ç±»å‹ï¼Œé»˜è®¤ "gradual_discharge"

    Returns:
        æ—¶åºæ•°æ®åˆ—è¡¨
    """
    loader = DataLoader()
    return loader.load_timeseries(device_id, evolution_type)


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    print("=" * 70)
    print("æ•°æ®åŠ è½½å™¨æµ‹è¯•")
    print("=" * 70)

    loader = DataLoader()

    # è·å–æ•°æ®é›†æ¦‚è§ˆ
    print("\næ•°æ®é›†æ¦‚è§ˆ:")
    summary = loader.get_summary()
    print(f"  å¯ç”¨è®¾å¤‡: {summary.get('devices', [])}")
    print(f"  å¯ç”¨åœºæ™¯: {summary.get('scenarios', [])}")
    print(f"  æ•…éšœç±»å‹: {summary.get('fault_types', [])}")

    # æµ‹è¯•åŠ è½½åœºæ™¯
    print("\nåŠ è½½æ··åˆåœºæ™¯:")
    mixed = loader.load_scenario("mixed")
    for device in mixed:
        severity_icon = "âš ï¸ " if device["severity"] >= 2 else ("ğŸŸ¡" if device["severity"] == 1 else "âœ…")
        print(f"  {severity_icon} {device['device_id']}: {device['fault_type']} "
              f"(ä¸¥é‡ç¨‹åº¦: {device['severity']})")

    # æµ‹è¯•åŠ è½½è®¾å¤‡
    print("\nåŠ è½½T001è®¾å¤‡ (é«˜èƒ½é‡æ”¾ç”µ):")
    device = loader.load_device_snapshot("T001", "high_energy_discharge")
    print(f"  è®¾å¤‡: {device['device_id']}")
    print(f"  æ•…éšœ: {device['fault_type']}")
    print(f"  çƒ­ç‚¹æ¸©åº¦: {device['thermal']['hotspot_temp']:.1f}Â°C")
    print(f"  C2H2: {device['dga']['C2H2']:.1f} ppm")

    # æµ‹è¯•åŠ è½½æ—¶åºæ•°æ®
    print("\nåŠ è½½T001æ—¶åºæ•°æ® (é€æ¸æ”¾ç”µ):")
    timeseries = loader.load_timeseries("T001", "gradual_discharge")
    print(f"  æ•°æ®ç‚¹æ•°: {len(timeseries)}")
    print(f"  èµ·å§‹æ—¶é—´: {timeseries[0]['timestamp']}")
    print(f"  ç»“æŸæ—¶é—´: {timeseries[-1]['timestamp']}")
    print(f"  åˆå§‹DP: {timeseries[0]['aging']['current_dp']:.1f}")
    print(f"  æœ€ç»ˆDP: {timeseries[-1]['aging']['current_dp']:.1f}")

    print("\n" + "=" * 70)
    print("âœ… æ•°æ®åŠ è½½å™¨æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 70)
